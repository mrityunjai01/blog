<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Blog on Tech on Collection of Short Articles on ML</title>
    <link>/docs/</link>
    <description>Recent content in Blog on Tech on Collection of Short Articles on ML</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 13 Jul 2025 00:00:00 +0000</lastBuildDate>
    <atom:link href="/docs/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Zero-shot Retrieval With Priors</title>
      <link>/docs/ret_1/</link>
      <pubDate>Sun, 13 Jul 2025 00:00:00 +0000</pubDate>
      <guid>/docs/ret_1/</guid>
      <description>&lt;h1 id=&#34;introduction&#34;&gt;&#xA;  Introduction&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#introduction&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;Retrieval refers to searching for a response to a query from a large corpus of documents. In the context of information retrieval, it is often necessary to retrieve relevant documents or passages from a large collection based on a given query. This process is typically performed using various retrieval models that rank documents based on their relevance to the query.&lt;/p&gt;&#xA;&lt;p&gt;Zero-shot retrieval refers to retrieval without any prior training. This might seem a daunting task at the outset, but it has been observed that simple sparse models like BM25 which use lexical similarity have been shown to have promising generalization capability. One way to measure this capability is to evaluate it on benchmarks such as BEIR.&lt;/p&gt;</description>
    </item>
    <item>
      <title>5 Levels of Optimizing Tokenizer Training with Simple Python Code</title>
      <link>/docs/bpe_tokenizer_training/</link>
      <pubDate>Tue, 01 Apr 2025 00:00:00 +0000</pubDate>
      <guid>/docs/bpe_tokenizer_training/</guid>
      <description>&lt;h1 id=&#34;introduction&#34;&gt;&#xA;  Introduction&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#introduction&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;Tokenization of text from scratch typically involves three steps: Pretokenization, Training a tokenizer, Writing an encoder-decoder pair which uses the learned vocab and merges files generated by the tokenizer. Typically, the most time and memory consuming step is the training of the tokenizer. In this post, I will show five levels of optimization in the training of a BPE tokenizer in 5 levels, starting from a simple Python code and ending with an performant rust implementation.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Continuously Parametrizing Decision Trees</title>
      <link>/docs/param_dt/</link>
      <pubDate>Tue, 11 Mar 2025 00:00:00 +0000</pubDate>
      <guid>/docs/param_dt/</guid>
      <description>&lt;p&gt;There have been a lot of efforts into parametrizing decision trees in a continuous fashion, that is, making the tree&amp;rsquo;s prediction continuous with respect to its parameters. This is important because it is a first step towards differentiability of trees, which could result in an SGD optimization for fitting trees. However, most such efforts have failed because of some very fundamental problems in the definition of the decision trees&amp;rsquo; architecture. This makes a parametrization very difficult unless we drop architectural constraints.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Parametrizing Decision Trees</title>
      <link>/docs/search/</link>
      <pubDate>Tue, 11 Mar 2025 00:00:00 +0000</pubDate>
      <guid>/docs/search/</guid>
      <description>&lt;p&gt;References:&#xA;[https://learn.microsoft.com/en-us/azure/search/search-relevance-overview]&#xA;[https://learn.microsoft.com/en-us/azure/search/hybrid-search-ranking]&lt;/p&gt;</description>
    </item>
    <item>
      <title>Reddit Astroturfing: A Bayesian Approach</title>
      <link>/docs/reddit_astroturfing/</link>
      <pubDate>Tue, 11 Mar 2025 00:00:00 +0000</pubDate>
      <guid>/docs/reddit_astroturfing/</guid>
      <description>&lt;h2 id=&#34;introduction&#34;&gt;&#xA;  Introduction&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#introduction&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;We&amp;rsquo;ve all come across reddit posts with controversial or opinionated claims and are surprised by the number of supporting comments they receive. At times, this is merely a function of genuine support for contrarian viewpoints. However, if I come across the same small subset of users promoting a particular narrative, I sometimes begin to question if there&amp;rsquo;s a bit of a systematic component to it. There is some chance that a group of users collude to write group-affirming comments, perhaps supported or controlled by a single entity. This is usually suspicious if there&amp;rsquo;s very little activity from such astroturfing users apart from such posts.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Can Machines Search for Omitted Variables?</title>
      <link>/docs/omitted_vars/</link>
      <pubDate>Sun, 13 Oct 2024 00:00:00 +0000</pubDate>
      <guid>/docs/omitted_vars/</guid>
      <description>&lt;!-- markdownlint-disable MD025 MD013 --&gt;&#xA;&lt;p&gt;There&amp;rsquo;s some consensus that a lot of methods which are used to detect omitted variables don&amp;rsquo;t works well if the omitted feature is not correlated with the covariates. This causes a problem when trying to detect possible omission of variables. In this post, I will show that even if we know that there is omission, we can&amp;rsquo;t identify omitted variables by only using analytical methods. We need to bring practical information in to ascertain causality, we&amp;rsquo;re otherwise left with a set of possible correlated variables.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Snooping in Technical Trading</title>
      <link>/docs/technical_trading/</link>
      <pubDate>Sun, 13 Oct 2024 00:00:00 +0000</pubDate>
      <guid>/docs/technical_trading/</guid>
      <description>&lt;!-- markdownlint-disable MD025 MD013 --&gt;&#xA;&lt;h1 id=&#34;introduction&#34;&gt;&#xA;  Introduction&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#introduction&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;Technical Trading is defined by the exclusive use of data from past prices and volumes to make trading decisions. It has been widely contested that technical trading doesn&amp;rsquo;t outperform major benchmarks owing to the weak form of the Efficient Market Hypothesis (EMH). However, there are many who believe that technical trading can be profitable, especially when combined with other methods such as fundamental analysis or machine learning. This is especially true when some strategies outperform benchmarks in back-test, leading researchers to claim that those strategies are profitable.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Maximum Likelihood Estimation for Neural Networks</title>
      <link>/docs/mle_nn/</link>
      <pubDate>Tue, 01 Oct 2024 00:00:00 +0000</pubDate>
      <guid>/docs/mle_nn/</guid>
      <description>&lt;!-- markdownlint-disable MD025 MD013 --&gt;&#xA;&lt;h1 id=&#34;maximum-likelihood-estimation-for-neural-networks&#34;&gt;&#xA;  Maximum Likelihood Estimation for Neural Networks&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#maximum-likelihood-estimation-for-neural-networks&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;&#xA;  Introduction&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#introduction&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;In this article, I&amp;rsquo;ll talk about the issues that Maximum Likelihood Estimation faces with Neural Networks. Maximum Likelihood Estimation is a concept that allows us to estimate parameters of a statistical model. Most models can be thought of as random variables which are functions of some parameters (weights and biases). These weights and biases, combined with some random draws from fundamental distributions (e.g., Gaussian, Bernoulli), can be said to generate data. The combination of weights and draws from random distributions is called a model which is supposed to describe the relationship between inputs \(x_i\) and outputs \(y_i\). The goal of MLE is to find the parameters that maximize the likelihood of observing the given data \(x_i\) and \(y_i\), where \(i\) comes from an indexing set.&lt;/p&gt;</description>
    </item>
    <item>
      <title>SPAN</title>
      <link>/docs/span/</link>
      <pubDate>Tue, 01 Oct 2024 00:00:00 +0000</pubDate>
      <guid>/docs/span/</guid>
      <description>&lt;!-- markdownlint-disable MD025 MD013 --&gt;</description>
    </item>
    <item>
      <title></title>
      <link>/docs/bayes_nn/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/docs/bayes_nn/</guid>
      <description></description>
    </item>
  </channel>
</rss>
